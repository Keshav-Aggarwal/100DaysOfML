{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow Classification Template.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "oFd0yka_0-Ul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "frMPmKbS4bZQ",
        "colab_type": "code",
        "outputId": "0989564b-bc6e-4ccd-95fe-2055ea116b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm\n",
        "tf.set_random_seed(10)\n",
        "np.random.seed(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.27.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t_rUd1Q1xeOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('https://github.com/harveenchadha/dump-nn-tf/raw/master/Section2/NN_Predict_Fraud/train.csv')\n",
        "df.head()\n",
        "df.dropna(inplace=True)\n",
        "x = df.iloc[:, :30]\n",
        "y = df.iloc[:, -1:]\n",
        "\n",
        "scl = StandardScaler()\n",
        "x = scl.fit_transform(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUeGUaMN0-Uw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def WeightsVariable(shape, name = 'weights'):\n",
        "    return tf.Variable(tf.truncated_normal(shape, mean = 0.0, stddev=0.001, name=name))\n",
        "\n",
        "def BiasVariable(shape, name = 'biases'):\n",
        "    return tf.Variable(tf.constant(1.0, shape=[shape], name='biases'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IC-wHEcH0-Uz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def network(images, channels = 1):\n",
        "    num_c = [128, 64, 64, 64, 32, 128]\n",
        "\n",
        "    with tf.name_scope('fc1'):\n",
        "        weights = WeightsVariable([30, num_c[0]])\n",
        "        biases = BiasVariable(num_c[0])\n",
        "        fc1 = tf.nn.relu(tf.matmul(images, weights) + biases)\n",
        "        \n",
        "    with tf.name_scope('fc2'):\n",
        "        weights = WeightsVariable([num_c[0], num_c[1]])\n",
        "        biases = BiasVariable(num_c[1])\n",
        "        fc1 = tf.nn.relu(tf.matmul(fc1, weights) + biases)\n",
        "        \n",
        "    with tf.name_scope('fc3'):\n",
        "        weights = WeightsVariable([num_c[1], num_c[2]])\n",
        "        biases = BiasVariable(num_c[2])\n",
        "        fc1 = tf.nn.relu(tf.matmul(fc1, weights) + biases)\n",
        "        \n",
        "    with tf.name_scope('fc5'):\n",
        "        weights = WeightsVariable([num_c[2], num_c[3]])\n",
        "        biases = BiasVariable(num_c[3])\n",
        "        fc1 = tf.nn.relu(tf.matmul(fc1, weights) + biases)\n",
        "        \n",
        "    with tf.name_scope('fc6'):\n",
        "        weights = WeightsVariable([num_c[3], num_c[4]])\n",
        "        biases = BiasVariable(num_c[4])\n",
        "        fc1 = tf.nn.relu(tf.matmul(fc1, weights) + biases)   \n",
        "\n",
        "    with tf.name_scope('fc4'):\n",
        "        weights = WeightsVariable([num_c[4], 1])\n",
        "        biases = BiasVariable(1)\n",
        "        fc2 = tf.matmul(fc1, weights) + biases\n",
        "    return fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AEWbuvcQ0-U2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_metrics(logits, labels):\n",
        "    logits = logits\n",
        "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, \n",
        "                                                                   logits = logits, \n",
        "                                                                   name = 'softmax')\n",
        "    return tf.reduce_mean(cross_entropy, name = 'softmax_mean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJLUwfZX0-U6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#returns the optimizer by taking the loss\n",
        "def training(loss):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = STARTER_LR)\n",
        "    train_op = optimizer.minimize(loss)\n",
        "    return train_op\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "57j_wcyV0-U9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluation(logits, labels):\n",
        "    correct = tf.nn.in_top_k(logits, labels, k = 1)\n",
        "    return tf.reduce_sum(tf.cast(correct, tf.int32))#, accuracy1, accuracy2\n",
        "  \n",
        "def acc(logits, labels):\n",
        "    correct_prediction = tf.equal(tf.cast(tf.greater_equal(logits,0.5), tf.float32) , labels)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgIUHWfj0-VG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def placeholder_inputs(batch_size, shape = [30]):\n",
        "    image_placeholder = tf.placeholder(tf.float32, shape = (None, shape[0]))\n",
        "    label_placeholder = tf.placeholder(tf.float32, shape = (None))\n",
        "    return image_placeholder, label_placeholder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Za5Tlllw0-VN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "loss_plot = []\n",
        "acc_plot = []\n",
        "train_plot = []\n",
        "def run_training(x, y):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
        "    with tf.Graph().as_default():\n",
        "\n",
        "        images_pl, labels_pl = placeholder_inputs(BATCH_SIZE)\n",
        "        logits = network(images_pl)\n",
        "        print(\"Logits Calculated Successfully\")\n",
        "        loss = loss_metrics(logits = logits, labels = labels_pl)\n",
        "        train_op = training(loss)\n",
        "#         eval_correct = evaluation(logits, labels_pl)\n",
        "        acc_val = acc(logits, labels_pl)\n",
        "        summary = tf.summary.merge_all()\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        \n",
        "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9) #OPTIONAL\n",
        "        sess = tf.Session(config=tf.ConfigProto(gpu_options = gpu_options))\n",
        "        \n",
        "        saver = tf.train.Saver()\n",
        "        sess.run(init)\n",
        "        for steps in range(MAX_STEPS):\n",
        "            loss_avg = []\n",
        "            for i in tqdm(np.arange(0, len(x_train), BATCH_SIZE)):\n",
        "                images_feed = x_train[i*BATCH_SIZE:i*(BATCH_SIZE+1)]\n",
        "                labels_feed = y_train[i*BATCH_SIZE:i*(BATCH_SIZE+1)]\n",
        "\n",
        "                feed_dict = { images_pl: np.reshape(images_feed, (-1, 30)), labels_pl: labels_feed }\n",
        "\n",
        "                _ = sess.run([train_op], feed_dict = feed_dict)\n",
        "                \n",
        "\n",
        "            images_feed = x_test\n",
        "            labels_feed = y_test\n",
        "\n",
        "            feed_dict = {\n",
        "                images_pl: np.reshape(images_feed, (-1, 30)),\n",
        "                labels_pl: labels_feed\n",
        "                        }\n",
        "            loss_  = sess.run([loss], feed_dict = feed_dict)\n",
        "            accuracy_val  = sess.run([acc_val], feed_dict = feed_dict)\n",
        "            \n",
        "            images_feed = x_train\n",
        "            labels_feed = y_train\n",
        "\n",
        "            feed_dict = {\n",
        "                images_pl: np.reshape(images_feed, (-1, 30)),\n",
        "                labels_pl: labels_feed\n",
        "                        }\n",
        "            train_loss  = sess.run([loss], feed_dict = feed_dict)\n",
        "            \n",
        "            loss_plot.append(loss_)\n",
        "            train_plot.append(train_loss)\n",
        "            acc_plot.append(accuracy_val)\n",
        "            print('\\t Loss %d: Training loss = %.5f  Validation loss = %.5f\\t Validation Acc = %.5f' % (steps+1, train_loss[0], loss_[0], accuracy_val[0]))     \n",
        "          \n",
        "        return sess, images_pl, labels_pl, acc_val, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "PBg_gG-g0-VV",
        "colab_type": "code",
        "outputId": "2fccb870-a17d-4236-e9bc-5f80f5fcb159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        }
      },
      "cell_type": "code",
      "source": [
        "STARTER_LR = 6e-5\n",
        "BATCH_SIZE = 4\n",
        "NUM_CLASSES = 10\n",
        "MAX_STEPS = 100\n",
        "\n",
        "loss_plot = []\n",
        "acc_plot = []\n",
        "train_plot = []\n",
        "sess, images_pl, labels_pl, eval_correct, logits = run_training(np.asarray(x, dtype = np.float32), np.asarray(y, dtype = np.int32))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logits Calculated Successfully\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 760.37it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1146.72it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 1: Training loss = 0.77248  Validation loss = 0.85259\t Validation Acc = 0.42778\n",
            "\t Loss 2: Training loss = 0.70806  Validation loss = 0.74911\t Validation Acc = 0.57222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1167.42it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1175.61it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 3: Training loss = 0.69625  Validation loss = 0.73223\t Validation Acc = 0.57222\n",
            "\t Loss 4: Training loss = 0.67949  Validation loss = 0.70796\t Validation Acc = 0.57222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1193.08it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1308.11it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 5: Training loss = 0.66769  Validation loss = 0.69450\t Validation Acc = 0.66667\n",
            "\t Loss 6: Training loss = 0.65842  Validation loss = 0.68492\t Validation Acc = 0.68333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1247.97it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1178.22it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 7: Training loss = 0.64855  Validation loss = 0.67433\t Validation Acc = 0.70556\n",
            "\t Loss 8: Training loss = 0.63825  Validation loss = 0.66301\t Validation Acc = 0.71667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1092.85it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1296.37it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 9: Training loss = 0.62788  Validation loss = 0.65134\t Validation Acc = 0.72778\n",
            "\t Loss 10: Training loss = 0.61717  Validation loss = 0.63886\t Validation Acc = 0.73333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1265.74it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1307.52it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 11: Training loss = 0.60669  Validation loss = 0.62639\t Validation Acc = 0.76111\n",
            "\t Loss 12: Training loss = 0.59590  Validation loss = 0.61331\t Validation Acc = 0.78333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1236.16it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1298.78it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 13: Training loss = 0.58495  Validation loss = 0.59984\t Validation Acc = 0.78889\n",
            "\t Loss 14: Training loss = 0.57414  Validation loss = 0.58652\t Validation Acc = 0.78889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1216.81it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1310.51it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 15: Training loss = 0.56371  Validation loss = 0.57364\t Validation Acc = 0.79444\n",
            "\t Loss 16: Training loss = 0.55399  Validation loss = 0.56174\t Validation Acc = 0.79444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1254.05it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1303.48it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 17: Training loss = 0.54430  Validation loss = 0.54975\t Validation Acc = 0.80000\n",
            "\t Loss 18: Training loss = 0.53527  Validation loss = 0.53875\t Validation Acc = 0.80556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1190.01it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1295.24it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 19: Training loss = 0.52636  Validation loss = 0.52788\t Validation Acc = 0.80556\n",
            "\t Loss 20: Training loss = 0.51792  Validation loss = 0.51761\t Validation Acc = 0.80556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1248.56it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1270.54it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 21: Training loss = 0.50945  Validation loss = 0.50719\t Validation Acc = 0.81667\n",
            "\t Loss 22: Training loss = 0.50394  Validation loss = 0.50123\t Validation Acc = 0.82778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1263.36it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1308.35it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 23: Training loss = 0.49452  Validation loss = 0.48926\t Validation Acc = 0.82778\n",
            "\t Loss 24: Training loss = 0.48493  Validation loss = 0.47711\t Validation Acc = 0.82778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1262.68it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1294.77it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 25: Training loss = 0.47622  Validation loss = 0.46624\t Validation Acc = 0.82778\n",
            "\t Loss 26: Training loss = 0.46733  Validation loss = 0.45525\t Validation Acc = 0.82778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1212.01it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1258.57it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 27: Training loss = 0.46028  Validation loss = 0.44726\t Validation Acc = 0.84444\n",
            "\t Loss 28: Training loss = 0.45238  Validation loss = 0.43799\t Validation Acc = 0.84444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1235.23it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1280.30it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 29: Training loss = 0.44311  Validation loss = 0.42636\t Validation Acc = 0.84444\n",
            "\t Loss 30: Training loss = 0.44058  Validation loss = 0.42577\t Validation Acc = 0.85000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1267.82it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1269.73it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 31: Training loss = 0.43349  Validation loss = 0.41775\t Validation Acc = 0.86111\n",
            "\t Loss 32: Training loss = 0.41646  Validation loss = 0.39322\t Validation Acc = 0.85000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1273.95it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1289.01it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 33: Training loss = 0.40908  Validation loss = 0.38491\t Validation Acc = 0.85556\n",
            "\t Loss 34: Training loss = 0.39272  Validation loss = 0.35880\t Validation Acc = 0.85000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1259.33it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1276.66it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 35: Training loss = 0.38448  Validation loss = 0.33231\t Validation Acc = 0.83333\n",
            "\t Loss 36: Training loss = 0.38593  Validation loss = 0.32714\t Validation Acc = 0.82778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1196.43it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1289.55it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 37: Training loss = 0.38367  Validation loss = 0.31988\t Validation Acc = 0.82778\n",
            "\t Loss 38: Training loss = 0.37791  Validation loss = 0.31308\t Validation Acc = 0.83889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1231.78it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1298.16it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 39: Training loss = 0.37649  Validation loss = 0.30882\t Validation Acc = 0.83889\n",
            "\t Loss 40: Training loss = 0.37255  Validation loss = 0.30444\t Validation Acc = 0.84444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1224.41it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1307.25it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 41: Training loss = 0.36839  Validation loss = 0.29979\t Validation Acc = 0.84444\n",
            "\t Loss 42: Training loss = 0.36682  Validation loss = 0.29531\t Validation Acc = 0.85556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1217.46it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1270.26it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 43: Training loss = 0.36003  Validation loss = 0.28869\t Validation Acc = 0.85556\n",
            "\t Loss 44: Training loss = 0.35810  Validation loss = 0.28677\t Validation Acc = 0.85556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1259.85it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1291.18it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 45: Training loss = 0.35161  Validation loss = 0.27989\t Validation Acc = 0.87222\n",
            "\t Loss 46: Training loss = 0.35307  Validation loss = 0.27917\t Validation Acc = 0.87222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1240.25it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1261.04it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 47: Training loss = 0.34631  Validation loss = 0.27274\t Validation Acc = 0.88333\n",
            "\t Loss 48: Training loss = 0.34089  Validation loss = 0.26772\t Validation Acc = 0.88889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1242.36it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1304.38it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 49: Training loss = 0.34000  Validation loss = 0.26482\t Validation Acc = 0.88889\n",
            "\t Loss 50: Training loss = 0.33099  Validation loss = 0.25820\t Validation Acc = 0.88889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1266.94it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1274.84it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 51: Training loss = 0.33512  Validation loss = 0.25888\t Validation Acc = 0.88889\n",
            "\t Loss 52: Training loss = 0.31465  Validation loss = 0.24610\t Validation Acc = 0.90000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1227.65it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1275.26it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 53: Training loss = 0.32416  Validation loss = 0.25012\t Validation Acc = 0.88889\n",
            "\t Loss 54: Training loss = 0.31238  Validation loss = 0.24067\t Validation Acc = 0.90000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1235.45it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1242.80it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 55: Training loss = 0.31605  Validation loss = 0.24216\t Validation Acc = 0.90000\n",
            "\t Loss 56: Training loss = 0.30723  Validation loss = 0.23482\t Validation Acc = 0.90000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1246.36it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1274.30it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 57: Training loss = 0.30796  Validation loss = 0.23440\t Validation Acc = 0.90000\n",
            "\t Loss 58: Training loss = 0.30128  Validation loss = 0.22901\t Validation Acc = 0.90556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1253.74it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1235.15it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 59: Training loss = 0.29962  Validation loss = 0.22696\t Validation Acc = 0.91111\n",
            "\t Loss 60: Training loss = 0.29450  Validation loss = 0.22242\t Validation Acc = 0.91667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1230.01it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1296.17it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 61: Training loss = 0.29152  Validation loss = 0.21927\t Validation Acc = 0.91667\n",
            "\t Loss 62: Training loss = 0.28538  Validation loss = 0.21426\t Validation Acc = 0.92222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1234.18it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1269.17it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 63: Training loss = 0.28598  Validation loss = 0.21337\t Validation Acc = 0.92222\n",
            "\t Loss 64: Training loss = 0.27926  Validation loss = 0.20771\t Validation Acc = 0.92778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1252.41it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1258.59it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 65: Training loss = 0.27696  Validation loss = 0.20521\t Validation Acc = 0.92778\n",
            "\t Loss 66: Training loss = 0.27057  Validation loss = 0.20005\t Validation Acc = 0.92778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1211.96it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1288.99it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 67: Training loss = 0.27302  Validation loss = 0.20064\t Validation Acc = 0.92778\n",
            "\t Loss 68: Training loss = 0.26733  Validation loss = 0.19545\t Validation Acc = 0.92778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1234.09it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1276.93it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 69: Training loss = 0.26308  Validation loss = 0.19158\t Validation Acc = 0.92778\n",
            "\t Loss 70: Training loss = 0.26069  Validation loss = 0.18916\t Validation Acc = 0.92778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1243.16it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1286.85it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 71: Training loss = 0.25726  Validation loss = 0.18603\t Validation Acc = 0.92778\n",
            "\t Loss 72: Training loss = 0.25444  Validation loss = 0.18338\t Validation Acc = 0.92778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1220.69it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1287.15it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 73: Training loss = 0.25008  Validation loss = 0.17955\t Validation Acc = 0.92778\n",
            "\t Loss 74: Training loss = 0.24752  Validation loss = 0.17715\t Validation Acc = 0.93333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1258.97it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1317.15it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 75: Training loss = 0.24405  Validation loss = 0.17392\t Validation Acc = 0.93333\n",
            "\t Loss 76: Training loss = 0.24340  Validation loss = 0.17299\t Validation Acc = 0.93333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1260.33it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1255.14it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 77: Training loss = 0.23918  Validation loss = 0.16909\t Validation Acc = 0.93333\n",
            "\t Loss 78: Training loss = 0.23791  Validation loss = 0.16770\t Validation Acc = 0.93333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1275.23it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1278.03it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 79: Training loss = 0.23432  Validation loss = 0.16427\t Validation Acc = 0.93333\n",
            "\t Loss 80: Training loss = 0.23407  Validation loss = 0.16381\t Validation Acc = 0.93333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1281.59it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1279.43it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 81: Training loss = 0.22840  Validation loss = 0.15876\t Validation Acc = 0.93333\n",
            "\t Loss 82: Training loss = 0.23179  Validation loss = 0.16118\t Validation Acc = 0.93333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1279.18it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1294.49it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 83: Training loss = 0.22490  Validation loss = 0.15505\t Validation Acc = 0.93333\n",
            "\t Loss 84: Training loss = 0.22625  Validation loss = 0.15587\t Validation Acc = 0.93889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1189.34it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1294.97it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 85: Training loss = 0.22155  Validation loss = 0.15168\t Validation Acc = 0.93889\n",
            "\t Loss 86: Training loss = 0.22324  Validation loss = 0.15259\t Validation Acc = 0.93889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1265.59it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1333.12it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 87: Training loss = 0.21406  Validation loss = 0.14504\t Validation Acc = 0.93889\n",
            "\t Loss 88: Training loss = 0.22171  Validation loss = 0.15083\t Validation Acc = 0.93889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1242.96it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1311.57it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 89: Training loss = 0.21157  Validation loss = 0.14287\t Validation Acc = 0.93889\n",
            "\t Loss 90: Training loss = 0.21242  Validation loss = 0.14306\t Validation Acc = 0.93889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1227.71it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1299.95it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 91: Training loss = 0.20495  Validation loss = 0.13743\t Validation Acc = 0.94444\n",
            "\t Loss 92: Training loss = 0.21151  Validation loss = 0.14181\t Validation Acc = 0.93889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1238.31it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1266.63it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 93: Training loss = 0.20080  Validation loss = 0.13381\t Validation Acc = 0.94444\n",
            "\t Loss 94: Training loss = 0.20427  Validation loss = 0.13618\t Validation Acc = 0.94444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1236.18it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1270.32it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 95: Training loss = 0.19543  Validation loss = 0.13002\t Validation Acc = 0.94444\n",
            "\t Loss 96: Training loss = 0.20032  Validation loss = 0.13258\t Validation Acc = 0.94444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1279.88it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1272.91it/s]\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 97: Training loss = 0.19725  Validation loss = 0.13017\t Validation Acc = 0.94444\n",
            "\t Loss 98: Training loss = 0.19074  Validation loss = 0.12558\t Validation Acc = 0.95000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 180/180 [00:00<00:00, 1244.38it/s]\n",
            "100%|██████████| 180/180 [00:00<00:00, 1262.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 99: Training loss = 0.19859  Validation loss = 0.13037\t Validation Acc = 0.95000\n",
            "\t Loss 100: Training loss = 0.18967  Validation loss = 0.12415\t Validation Acc = 0.95000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qbl9eEQrZauX",
        "colab_type": "code",
        "outputId": "d8178fbd-2e04-4aa4-bc7f-955851bafb96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "plt.plot(acc_plot,'g-',label=\"Validation Acc\")\n",
        "plt.plot(loss_plot, 'b-', label=\"Validation Loss\")\n",
        "plt.plot(train_plot, \"r-\", label='Training Loss')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7feb05b08390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7feb04252668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bPsgRXIYABWN",
        "colab_type": "code",
        "outputId": "790e0499-9275-4533-fad4-cf1f175fc775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "images_feed, labels_feed = MNIST_DATASETS.validation.images, MNIST_DATASETS.validation.labels\n",
        "\n",
        "feed_dict = {\n",
        "    images_pl: np.reshape(images_feed, (-1, 28, 28, 1))\n",
        "            }\n",
        "with sess.as_default():\n",
        "  accuracy  = sess.run([logits], feed_dict = feed_dict)\n",
        "  \n",
        "  preds = np.argmax(accuracy[0], 1)\n",
        "  print(preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 ... 2 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zl6bKEbGa2Ay",
        "colab_type": "code",
        "outputId": "07a13f1a-b101-4dc7-b37c-0eb043e34b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels_feed, preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.99      0.99      0.99       479\n",
            "          1       0.97      0.98      0.97       563\n",
            "          2       0.98      0.93      0.96       488\n",
            "          3       0.98      0.96      0.97       493\n",
            "          4       0.98      0.98      0.98       535\n",
            "          5       0.96      0.98      0.97       434\n",
            "          6       0.98      0.98      0.98       501\n",
            "          7       0.96      0.97      0.97       550\n",
            "          8       0.96      0.97      0.97       462\n",
            "          9       0.96      0.96      0.96       495\n",
            "\n",
            "avg / total       0.97      0.97      0.97      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c5xuDiGTi2Pv",
        "colab_type": "code",
        "outputId": "dd8f7495-7389-4fda-ece7-3f762849dc41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(labels_feed, preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[473   0   0   0   0   2   2   0   0   2]\n",
            " [  0 553   2   2   1   0   1   2   2   0]\n",
            " [  1  10 454   5   1   1   0   7   8   1]\n",
            " [  0   1   2 475   0   7   0   5   2   1]\n",
            " [  0   1   0   0 526   0   4   1   0   3]\n",
            " [  0   1   1   0   1 427   0   0   3   1]\n",
            " [  3   2   0   0   1   1 493   0   1   0]\n",
            " [  0   2   2   1   3   0   0 536   0   6]\n",
            " [  0   2   0   1   0   3   1   2 449   4]\n",
            " [  2   1   0   2   5   2   0   7   2 474]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6DmDZXWY0-VZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# graph = tf.GraphDef()\n",
        "# graph.ParseFromString(tf_model.SerializeToString())\n",
        "\n",
        "# with tf.Graph().as_default() as graph:\n",
        "#         # The name var will prefix every op/nodes in your graph\n",
        "#         # Since we load everything in a new graph, this is not needed\n",
        "#     tf.import_graph_def(graph, name=\"prefix\")\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}