{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow Classification Template.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oFd0yka_0-Ul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "frMPmKbS4bZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a277a441-d74e-4c4e-c701-e647989dba14"
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm\n",
        "tf.set_random_seed(10)\n",
        "np.random.seed(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.27.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "veAWnxz80-VQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "4ea87ec5-5826-4b9f-9527-1842864693a6"
      },
      "cell_type": "code",
      "source": [
        "MNIST_DATASETS = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-e0b27bad68fd>:1: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Ynn1r_c0-Us",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "STARTER_LR = 1e-4\n",
        "BATCH_SIZE = 100\n",
        "NUM_CLASSES = 10\n",
        "MAX_STEPS = 3\n",
        "IMAGE_SIZE = 28\n",
        "OUTPUT_NAMES = ['fc2/add']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUeGUaMN0-Uw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def WeightsVariable(shape, name = 'weights'):\n",
        "    return tf.Variable(tf.truncated_normal(shape, mean = 0.0, stddev=0.01, name=name))\n",
        "\n",
        "def BiasVariable(shape, name = 'biases'):\n",
        "    return tf.Variable(tf.constant(0.1, shape=[shape], name='biases'))\n",
        "\n",
        "def Conv2d(x, W, B, stride = 1, padding = 'VALID', activation_fun = True):\n",
        "    filter_size = W.get_shape().as_list()\n",
        "    pad_size = filter_size[0] // 2\n",
        "    pad_mat = np.array([[0, 0], [pad_size, pad_size], [pad_size, pad_size], [0, 0]])\n",
        "    \n",
        "    x = tf.pad(x, pad_mat)\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding = padding)\n",
        "    x = tf.nn.bias_add(x, B)\n",
        "    \n",
        "    if(activation_fun == True):\n",
        "        return tf.nn.relu(x)\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def MaxPool2d(x, k = 2):\n",
        "    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'VALID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IC-wHEcH0-Uz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def network(images, channels = 1):\n",
        "    num_c = [8, 16, 32, 64, 64, 128]\n",
        "    #COONVOLUTION 1\n",
        "    with tf.name_scope('Conv1'):\n",
        "        weights = WeightsVariable([3, 3, channels, num_c[0]])\n",
        "        bias = BiasVariable(num_c[0])\n",
        "        conv1 = Conv2d(images, weights, bias)\n",
        "        \n",
        "    with tf.name_scope('Conv2_m'):\n",
        "        weights = WeightsVariable([3, 3, num_c[0], num_c[1]])\n",
        "        bias = BiasVariable(num_c[1])\n",
        "        conv2 = Conv2d(conv1, weights, bias)\n",
        "        pool1 = MaxPool2d(conv2)\n",
        "        \n",
        "    with tf.name_scope('Conv3'):\n",
        "        weights = WeightsVariable([3, 3, num_c[1], num_c[2]])\n",
        "        bias = BiasVariable(num_c[2])\n",
        "        conv3 = Conv2d(pool1, weights, bias)\n",
        "    \n",
        "    with tf.name_scope('Conv4_m'):\n",
        "        weights = WeightsVariable([3, 3, num_c[2], num_c[3]])\n",
        "        bias = BiasVariable(num_c[3])\n",
        "        conv4 = Conv2d(conv3, weights, bias)\n",
        "        pool2 = MaxPool2d(conv4)\n",
        "    \n",
        "    with tf.name_scope('flatten'):\n",
        "        flat = tf.layers.flatten(pool2)\n",
        "    \n",
        "    input_flat_shape = np.int32(flat.shape[1])\n",
        "    \n",
        "    with tf.name_scope('fc1'):\n",
        "        weights = WeightsVariable([input_flat_shape, 64])\n",
        "        biases = BiasVariable(64)\n",
        "        fc1 = tf.nn.relu(tf.matmul(flat, weights) + biases)\n",
        "\n",
        "    with tf.name_scope('fc2'):\n",
        "        weights = WeightsVariable([64, 10])\n",
        "        biases = BiasVariable(10)\n",
        "        fc2 = tf.matmul(fc1, weights) + biases\n",
        "    return fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AEWbuvcQ0-U2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_metrics(logits, labels):\n",
        "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels, \n",
        "                                                                   logits = logits, \n",
        "                                                                   name = 'softmax')\n",
        "    return tf.reduce_mean(cross_entropy, name = 'softmax_mean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJLUwfZX0-U6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#returns the optimizer by taking the loss\n",
        "def training(loss):\n",
        "    tf.summary.scalar('loss', loss)\n",
        "    global_step = tf.Variable(0, name = 'global_step', trainable = False)\n",
        "    \n",
        "    learning_rate = tf.train.exponential_decay(STARTER_LR, \n",
        "                                               global_step = global_step, \n",
        "                                               decay_steps = 1000, \n",
        "                                               decay_rate = 0.7, \n",
        "                                               staircase = True)\n",
        "\n",
        "    tf.summary.scalar('learning_rate', learning_rate)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001)\n",
        "    train_op = optimizer.minimize(loss)\n",
        "    return train_op\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "57j_wcyV0-U9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluation(logits, labels):\n",
        "    correct = tf.nn.in_top_k(logits, labels, k = 1)\n",
        "\n",
        "    return tf.reduce_sum(tf.cast(correct, tf.int32))#, accuracy1, accuracy2\n",
        "  \n",
        "def acc(logits, labels):\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1), name='correct_pred')\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zp-v0RYc0-VB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def do_eval(sess, eval_correct, image_placeholder, labels_placeholder, data_set, summary):\n",
        "    true_count = 0\n",
        "    steps_per_epoch = data_set.num_examples // BATCH_SIZE\n",
        "    \n",
        "    num_examples = steps_per_epoch * BATCH_SIZE\n",
        "    \n",
        "    for steps in range(steps_per_epoch):\n",
        "        feed_dict = fill_feed_dict(data_set, image_placeholder, labels_placeholder)\n",
        "        log, correctness = sess.run([eval_correct], feed_dict = feed_dict)\n",
        "        true_count += correctness\n",
        "    \n",
        "    precision = float(true_count) / num_examples\n",
        "#     tf.summary.scalar('Precision', tf.constant(precision))\n",
        "    print('Num examples %d, Num Correct: %d Precisiokn @ 1: %0.04f' %\n",
        "          (num_examples, true_count, precision))\n",
        "    \n",
        "    return log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgIUHWfj0-VG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def placeholder_inputs(batch_size, shape = [28, 28, 1]):\n",
        "    image_placeholder = tf.placeholder(tf.float32, shape = (None, shape[0], shape[1], shape[2]))\n",
        "    label_placeholder = tf.placeholder(tf.int32, shape = (None))\n",
        "    return image_placeholder, label_placeholder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fp2vpUl80-VK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fill_feed_dict(data_set, image_placeholder, label_placeholder):\n",
        "    images_feed, labels_feed = data_set.next_batch(BATCH_SIZE)\n",
        "    feed_dict = {\n",
        "        image_placeholder: np.reshape(images_feed, (-1, 28, 28, 1)),\n",
        "        label_placeholder: labels_feed\n",
        "                }\n",
        "    return feed_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Za5Tlllw0-VN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "loss_plot = []\n",
        "acc_plot = []\n",
        "def run_training(Dataset):\n",
        "    with tf.Graph().as_default():\n",
        "\n",
        "        images_pl, labels_pl = placeholder_inputs(BATCH_SIZE)\n",
        "        logits = network(images_pl)\n",
        "        loss = loss_metrics(logits = logits, labels = labels_pl)\n",
        "        train_op = training(loss)\n",
        "        eval_correct = evaluation(logits, labels_pl)\n",
        "        acc_val = acc(logits, labels_pl)\n",
        "        summary = tf.summary.merge_all()\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        \n",
        "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9) #OPTIONAL\n",
        "        sess = tf.Session(config=tf.ConfigProto(gpu_options = gpu_options))\n",
        "        \n",
        "        summary_writer = tf.summary.FileWriter(\"/tmp/tf/eg/log\", \n",
        "                                               graph = tf.get_default_graph())\n",
        "        test_writer = tf.summary.FileWriter(\"tmp/tf/eg/validation/log\", \n",
        "                                            graph = tf.get_default_graph())\n",
        "        saver = tf.train.Saver()\n",
        "        sess.run(init)\n",
        "        for steps in range(MAX_STEPS):\n",
        "            start_time = time.time()\n",
        "\n",
        "            for i in tqdm(np.arange(0, Dataset.train.num_examples, BATCH_SIZE)):\n",
        "                images_feed, labels_feed = Dataset.train.next_batch(BATCH_SIZE)\n",
        "\n",
        "                feed_dict = {\n",
        "                    images_pl: np.reshape(images_feed, (-1, 28, 28, 1)),\n",
        "                    labels_pl: labels_feed\n",
        "                            }\n",
        "\n",
        "                _ = sess.run([train_op], feed_dict = feed_dict)\n",
        "                duration = time.time() - start_time\n",
        "\n",
        "#                 if (steps%100 == 0):\n",
        "#                     print('Step %d: loss = %.2f (%.3f sec)' % (steps, loss_value, duration))\n",
        "#                     summary_str = sess.run(summary, feed_dict = feed_dict)\n",
        "#                     summary_writer.add_summary(summary_str, steps)\n",
        "#                     summary_writer.flush()\n",
        "\n",
        "#                 if (steps + 1) % 1000 == 0 or (steps + 1) == MAX_STEPS:\n",
        "#                     checkpoint_file = os.path.join(\"model\", \"model.ckpt\")\n",
        "#                     saver.save(sess, checkpoint_file, global_step=steps)\n",
        "#                     print('Validation Data Eval:')\n",
        "#                     log = do_eval(sess,\n",
        "#                                   eval_correct,\n",
        "#                                   images_pl,\n",
        "#                                   labels_pl,\n",
        "#                                   Dataset.validation,\n",
        "#                                   summary)\n",
        "#                     test_writer.add_summary(log, steps)\n",
        "\n",
        "            images_feed, labels_feed = Dataset.validation.images, Dataset.validation.labels\n",
        "\n",
        "            feed_dict = {\n",
        "                images_pl: np.reshape(images_feed, (-1, 28, 28, 1)),\n",
        "                labels_pl: labels_feed\n",
        "                        }\n",
        "            accuracy, loss  = sess.run([eval_correct, loss], feed_dict = feed_dict)\n",
        "            \n",
        "            loss_plot.append(loss)\n",
        "            acc_plot.append(accuracy)\n",
        "            print('\\t Loss %d: loss = %.2f\\t' % (steps+1, loss))     \n",
        "          \n",
        "        graphdef = tf.get_default_graph().as_graph_def()\n",
        "\n",
        "        frozen_graph = tf.graph_util.convert_variables_to_constants(sess,\n",
        "                                                                    graphdef,\n",
        "                                                                    OUTPUT_NAMES)\n",
        "        return tf.graph_util.remove_training_nodes(frozen_graph),sess, images_pl, labels_pl, eval_correct, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "PBg_gG-g0-VV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1679
        },
        "outputId": "062ec000-0969-489e-e55b-ef025908cc0c"
      },
      "cell_type": "code",
      "source": [
        "MAX_STEPS = 5\n",
        "loss_plot = []\n",
        "tf_model, sess, images_pl, labels_pl, eval_correct, logits = run_training(MNIST_DATASETS)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 550/550 [00:04<00:00, 111.46it/s]\n",
            "  2%|▏         | 13/550 [00:00<00:04, 120.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Loss 1: loss = 2.29\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 550/550 [00:04<00:00, 117.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    283\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 284\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    285\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3576\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[0;32m-> 3577\u001b[0;31m                                                            types_str))\n\u001b[0m\u001b[1;32m   3578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Can not convert a float32 into a Tensor or Operation.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-cfc07a9f3ab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMAX_STEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMNIST_DATASETS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-71-f0708f9bebd5>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(Dataset)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mlabels_pl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels_feed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                         }\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mloss_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1095\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \"\"\"\n\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \"\"\"\n\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    286\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    287\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    289\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
            "\u001b[0;31mTypeError\u001b[0m: Fetch argument 2.2862105 has invalid type <class 'numpy.float32'>, must be a string or Tensor. (Can not convert a float32 into a Tensor or Operation.)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qbl9eEQrZauX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "57cb17b0-e323-4cd6-c463-630bc3e80f00"
      },
      "cell_type": "code",
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "plt.plot(acc_plot)\n",
        "plt.show()\n",
        "plt.plot(loss_plot)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe8e8d15588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe8e8ccf4a8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncwK7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe8e8d6f6a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-L_wi9yJk4dk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84c3c93a-92c7-49ee-f141-47131b43c0b7"
      },
      "cell_type": "code",
      "source": [
        "images_feed, labels_feed = MNIST_DATASETS.validation.images, MNIST_DATASETS.validation.labels\n",
        "\n",
        "feed_dict = {\n",
        "    images_pl: np.reshape(images_feed, (-1, 28, 28, 1)),labels_pl: labels_feed\n",
        "            }\n",
        "with sess.as_default():\n",
        "  accuracy  = sess.run([eval_correct], feed_dict = feed_dict)\n",
        "  print(accuracy)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4860]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bPsgRXIYABWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "790e0499-9275-4533-fad4-cf1f175fc775"
      },
      "cell_type": "code",
      "source": [
        "images_feed, labels_feed = MNIST_DATASETS.validation.images, MNIST_DATASETS.validation.labels\n",
        "\n",
        "feed_dict = {\n",
        "    images_pl: np.reshape(images_feed, (-1, 28, 28, 1))\n",
        "            }\n",
        "with sess.as_default():\n",
        "  accuracy  = sess.run([logits], feed_dict = feed_dict)\n",
        "  \n",
        "  preds = np.argmax(accuracy[0], 1)\n",
        "  print(preds)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 ... 2 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zl6bKEbGa2Ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "07a13f1a-b101-4dc7-b37c-0eb043e34b93"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels_feed, preds))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.99      0.99      0.99       479\n",
            "          1       0.97      0.98      0.97       563\n",
            "          2       0.98      0.93      0.96       488\n",
            "          3       0.98      0.96      0.97       493\n",
            "          4       0.98      0.98      0.98       535\n",
            "          5       0.96      0.98      0.97       434\n",
            "          6       0.98      0.98      0.98       501\n",
            "          7       0.96      0.97      0.97       550\n",
            "          8       0.96      0.97      0.97       462\n",
            "          9       0.96      0.96      0.96       495\n",
            "\n",
            "avg / total       0.97      0.97      0.97      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c5xuDiGTi2Pv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dd8f7495-7389-4fda-ece7-3f762849dc41"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(labels_feed, preds))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[473   0   0   0   0   2   2   0   0   2]\n",
            " [  0 553   2   2   1   0   1   2   2   0]\n",
            " [  1  10 454   5   1   1   0   7   8   1]\n",
            " [  0   1   2 475   0   7   0   5   2   1]\n",
            " [  0   1   0   0 526   0   4   1   0   3]\n",
            " [  0   1   1   0   1 427   0   0   3   1]\n",
            " [  3   2   0   0   1   1 493   0   1   0]\n",
            " [  0   2   2   1   3   0   0 536   0   6]\n",
            " [  0   2   0   1   0   3   1   2 449   4]\n",
            " [  2   1   0   2   5   2   0   7   2 474]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6DmDZXWY0-VZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# graph = tf.GraphDef()\n",
        "# graph.ParseFromString(tf_model.SerializeToString())\n",
        "\n",
        "# with tf.Graph().as_default() as graph:\n",
        "#         # The name var will prefix every op/nodes in your graph\n",
        "#         # Since we load everything in a new graph, this is not needed\n",
        "#     tf.import_graph_def(graph, name=\"prefix\")\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}