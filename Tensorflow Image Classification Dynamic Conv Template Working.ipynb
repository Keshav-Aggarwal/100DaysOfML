{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow Classification Template.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oFd0yka_0-Ul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6311442-6a1c-4eaa-a913-12025ba2cbf2"
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.27.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "frMPmKbS4bZQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.set_random_seed(10)\n",
        "np.random.seed(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_rUd1Q1xeOG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "54d7c28c-9917-4a5e-8d60-e01e1df2ec5b"
      },
      "cell_type": "code",
      "source": [
        "MNIST_DATASETS = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
        "fashion_dataset = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "scl = StandardScaler()\n",
        "min_scl = MinMaxScaler()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-f90bd17e8234>:1: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lUeGUaMN0-Uw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def WeightsVariable(shape, num = 0):\n",
        "    name = 'weights' + str(num)\n",
        "    return tf.get_variable(name=name, initializer=tf.initializers.glorot_uniform(),shape=shape) #tf.nn tf.truncated_normal(shape, mean = 0.0, stddev=0.001, name=name))\n",
        "\n",
        "def BiasVariable(shape, name = 'biases'):\n",
        "    return tf.Variable(tf.constant(1.0, shape=[shape], name='biases'))\n",
        "  \n",
        "def Conv2d(x, W, B, stride = 1, padding = 'VALID', activation_fun = True):\n",
        "    filter_size = W.get_shape().as_list()\n",
        "    pad_size = filter_size[0] // 2\n",
        "    pad_mat = np.array([[0, 0], [pad_size, pad_size], [pad_size, pad_size], [0, 0]])\n",
        "    \n",
        "    x = tf.pad(x, pad_mat)\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding = padding)\n",
        "    x = tf.nn.bias_add(x, B)\n",
        "    \n",
        "    if(activation_fun == True):\n",
        "        return tf.nn.relu(x)\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def MaxPool2d(x, k = 2):\n",
        "    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'VALID')  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IC-wHEcH0-Uz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def network(images, channels = 1, input_channel = 3, output_shape = 3):\n",
        "#     num_c = [256, 128, 64, 32, 16, 8, 4]\n",
        "    filter_size = 3\n",
        "    num_i = 0\n",
        "    with tf.name_scope('conv0'):\n",
        "        weights = WeightsVariable([filter_size, filter_size, input_channel, num_c[num_i]], num = num_i)\n",
        "        biases = BiasVariable(num_c[num_i])\n",
        "        fc1 = Conv2d(images, weights, biases)\n",
        "    num_i += 1\n",
        "    \n",
        "    for i in range(len(num_c)-1):\n",
        "        name = 'conv1' + str(i+2)\n",
        "        \n",
        "        if num_c[num_i] == -1:\n",
        "            fc1 = MaxPool2d(fc1)\n",
        "        else:\n",
        "            prev_l = num_c[num_i - 1]\n",
        "            if num_c[num_i - 1] == -1:\n",
        "                prev_l = num_c[num_i - 2]\n",
        "            with tf.name_scope(name):\n",
        "                weights = WeightsVariable([filter_size, filter_size, prev_l, num_c[num_i]], num = num_i)\n",
        "                biases = BiasVariable(num_c[num_i])\n",
        "                fc1 = Conv2d(fc1, weights, biases)\n",
        "        num_i += 1\n",
        "        \n",
        "    with tf.name_scope('flatten'):\n",
        "        flat = tf.layers.flatten(fc1)\n",
        "        \n",
        "    input_flat_shape = np.int32(flat.shape[1])\n",
        "    num_f = [input_flat_shape, 64, 10]\n",
        "    num_if = 1\n",
        "\n",
        "    with tf.name_scope('fc1'):\n",
        "        weights = WeightsVariable([num_f[num_if-1], num_f[num_if]], num = num_i)\n",
        "        biases = BiasVariable(num_f[num_if])\n",
        "        fc1 = tf.nn.relu(tf.matmul(flat, weights) + biases)\n",
        "        \n",
        "    num_if+=1\n",
        "    num_i += 1\n",
        "    \n",
        "    with tf.name_scope('fc2'):\n",
        "        weights = WeightsVariable([num_f[num_if-1], num_f[num_if]], num = num_i)\n",
        "        biases = BiasVariable(num_f[num_if])\n",
        "        fc2 = tf.matmul(fc1, weights) + biases\n",
        "        \n",
        "    return fc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AEWbuvcQ0-U2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_metrics(logits, labels, output_shape=1):\n",
        "    logits = logits\n",
        "    if output_shape == 1:\n",
        "      cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, \n",
        "                                                                   logits = logits, \n",
        "                                                                   name = 'softmax')\n",
        "      \n",
        "    else:\n",
        "      cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels, \n",
        "                                                                   logits = logits, \n",
        "                                                                   name = 'softmax')\n",
        "    return tf.reduce_mean(cross_entropy, name = 'softmax_mean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJLUwfZX0-U6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#returns the optimizer by taking the loss\n",
        "def training(loss):\n",
        "    global_step = tf.Variable(0, name = 'global_step', trainable = False)\n",
        "    \n",
        "    learning_rate = tf.train.exponential_decay(STARTER_LR, \n",
        "                                               global_step = global_step, \n",
        "                                               decay_steps = 200, \n",
        "                                               decay_rate = 0.6, \n",
        "                                               staircase = True)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = STARTER_LR)\n",
        "    train_op = optimizer.minimize(loss)\n",
        "    return train_op\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "57j_wcyV0-U9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluation(logits, labels, output_shape = 1):\n",
        "    correct = tf.nn.in_top_k(logits, labels, k = 1)\n",
        "    return tf.reduce_sum(tf.cast(correct, tf.int32))#, accuracy1, accuracy2\n",
        "  \n",
        "def acc(logits, labels, output_shape = 1):\n",
        "  \n",
        "    if(output_shape == 1):\n",
        "        correct_prediction = tf.equal(tf.cast(tf.greater_equal(logits,0.5), tf.float32), tf.cast(labels, tf.float32))\n",
        "        \n",
        "    else:\n",
        "        correct_prediction = tf.equal(tf.argmax(logits, 1),  tf.cast(labels, tf.int64), name='correct_pred')\n",
        "    \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgIUHWfj0-VG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def placeholder_inputs(batch_size, input_shape=None, output_shape=1):\n",
        "    image_placeholder = tf.placeholder(tf.float32, shape = (None, input_shape[0], input_shape[1], input_shape[2]))\n",
        "    if output_shape == 1:\n",
        "      label_placeholder = tf.placeholder(tf.float32, shape = (None))\n",
        "    else:\n",
        "      label_placeholder = tf.placeholder(tf.int32, shape = (None))\n",
        "    return image_placeholder, label_placeholder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Za5Tlllw0-VN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "loss_plot = []\n",
        "acc_plot = []\n",
        "train_plot = []\n",
        "def run_training(x, y, input_shape=None, output_shape=1, test_data = None):\n",
        "    if test_data is not None:\n",
        "        x_test, y_test = test_data[0], test_data[1]\n",
        "        x_train = x\n",
        "        y_train = y\n",
        "        \n",
        "    else:\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
        "        \n",
        "    with tf.Graph().as_default():\n",
        "\n",
        "        images_pl, labels_pl = placeholder_inputs(BATCH_SIZE, input_shape=input_shape, output_shape = output_shape)\n",
        "        logits = network(images_pl, input_channel=input_shape[2], output_shape=output_shape)\n",
        "        \n",
        "        print(\"Logits Calculated Successfully\")\n",
        "        \n",
        "        loss = loss_metrics(logits = logits, labels = labels_pl, output_shape = output_shape)\n",
        "        train_op = training(loss)\n",
        "#         eval_correct = evaluation(logits, labels_pl)\n",
        "        acc_val = acc(logits, labels_pl, output_shape = output_shape)\n",
        "        summary = tf.summary.merge_all()\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        \n",
        "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9) #OPTIONAL\n",
        "        sess = tf.Session(config=tf.ConfigProto(gpu_options = gpu_options))\n",
        "        \n",
        "        saver = tf.train.Saver()\n",
        "        sess.run(init)\n",
        "        for steps in range(MAX_STEPS):\n",
        "            loss_avg = []\n",
        "\n",
        "            for i in tqdm(np.arange(0, len(x_train) - 1, BATCH_SIZE)):\n",
        "                images_feed = x_train[i : i + BATCH_SIZE]\n",
        "                labels_feed = y_train[i : i + BATCH_SIZE]\n",
        "                feed_dict = { images_pl: images_feed, labels_pl: labels_feed }\n",
        "                _ = sess.run([train_op], feed_dict = feed_dict)\n",
        "\n",
        "            images_feed = x_test\n",
        "            labels_feed = y_test\n",
        "\n",
        "            feed_dict = {\n",
        "                images_pl: images_feed,\n",
        "                labels_pl: labels_feed\n",
        "                }\n",
        "            loss_  = sess.run([loss], feed_dict = feed_dict)\n",
        "            accuracy_val  = sess.run([acc_val], feed_dict = feed_dict)\n",
        "            images_feed = x_train[:10000]\n",
        "            labels_feed = y_train[:10000]\n",
        "\n",
        "            feed_dict = {\n",
        "                images_pl: images_feed,\n",
        "                labels_pl: labels_feed\n",
        "                        }\n",
        "            train_loss  = sess.run([loss], feed_dict = feed_dict)\n",
        "            \n",
        "            loss_plot.append(loss_)\n",
        "            train_plot.append(train_loss)\n",
        "            acc_plot.append(accuracy_val)\n",
        "            print('\\nLoss %d: Training loss = %.5f  Validation loss = %.5f\\t Validation Acc = %.5f' % (steps+1, train_loss[0], loss_[0], accuracy_val[0]))     \n",
        "          \n",
        "        return sess, images_pl, labels_pl, acc_val, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "PBg_gG-g0-VV",
        "colab_type": "code",
        "outputId": "7d7ca212-d9bd-47e2-c277-ed89bb7f3e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2546
        }
      },
      "cell_type": "code",
      "source": [
        "train, test = fashion_dataset[0], fashion_dataset[1]\n",
        "x = train[0]\n",
        "y = train[1]\n",
        "\n",
        "x = np.reshape(x, [-1, 28, 28 ,1])\n",
        "x_test = test[0][:2000]\n",
        "y_test = test[1][:2000]\n",
        "\n",
        "test = []\n",
        "test.append(np.reshape(x_test, [-1, 28, 28 ,1]))\n",
        "test.append(y_test)\n",
        "# x = min_scl.fit_transform(x)\n",
        "shape = [28, 28, 1]\n",
        "x = np.asarray(x, dtype = np.float32)\n",
        "y = np.asarray(y, dtype = np.float32)\n",
        "\n",
        "STARTER_LR = 5e-5\n",
        "BATCH_SIZE = 64\n",
        "MAX_STEPS = 30\n",
        "num_c = [512, 256, -1, 128, -1, 64]\n",
        "\n",
        "loss_plot = []\n",
        "acc_plot = []\n",
        "train_plot = []\n",
        "sess, images_pl, labels_pl, eval_correct, logits = run_training(x, y, input_shape=shape, output_shape=12, test_data = test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logits Calculated Successfully\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [01:28<00:00, 10.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2000,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv0/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv0/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, weights0/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node softmax_mean/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_93_softmax_mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f3e1622c6c38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0macc_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrain_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-d12f9931e776>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(x, y, input_shape, output_shape, test_data)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mlabels_pl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels_feed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 }\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mloss_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0maccuracy_val\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mimages_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2000,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv0/Conv2D (defined at <ipython-input-4-f1be5da5805e>:14)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv0/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, weights0/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node softmax_mean/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_93_softmax_mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv0/Conv2D', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-f3e1622c6c38>\", line 24, in <module>\n    sess, images_pl, labels_pl, eval_correct, logits = run_training(x, y, input_shape=shape, output_shape=12, test_data = test)\n  File \"<ipython-input-10-d12f9931e776>\", line 17, in run_training\n    logits = network(images_pl, input_channel=input_shape[2], output_shape=output_shape)\n  File \"<ipython-input-5-33851cba9524>\", line 8, in network\n    fc1 = Conv2d(images, weights, biases)\n  File \"<ipython-input-4-f1be5da5805e>\", line 14, in Conv2d\n    x = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding = padding)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2000,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv0/Conv2D (defined at <ipython-input-4-f1be5da5805e>:14)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv0/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, weights0/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node softmax_mean/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_93_softmax_mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qbl9eEQrZauX",
        "colab_type": "code",
        "outputId": "2506ab59-9d76-4e0d-e65b-46ae577495a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "plt.plot(acc_plot,'g-',label=\"Validation Acc\")\n",
        "plt.plot(loss_plot, 'b--', label=\"Validation Loss\")\n",
        "plt.plot(train_plot, \"r--\", label='Training Loss')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f08d52034a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhRBCCJVIExZCCCFU8v99yP6Ebmw01gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f08da60f390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bPsgRXIYABWN",
        "colab_type": "code",
        "outputId": "cc0733d1-09e5-4405-f0cb-ce2f1b65d5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "images_feed, labels_feed = MNIST_DATASETS.validation.images, MNIST_DATASETS.validation.labels\n",
        "\n",
        "feed_dict = {\n",
        "    images_pl: np.reshape(images_feed, (-1, 28, 28, 1))\n",
        "            }\n",
        "with sess.as_default():\n",
        "  accuracy  = sess.run([logits], feed_dict = feed_dict)\n",
        "  \n",
        "  preds = np.argmax(accuracy[0], 1)\n",
        "  print(preds)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d24bda0b91e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST_DATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMNIST_DATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m feed_dict = {\n\u001b[1;32m      4\u001b[0m     \u001b[0mimages_pl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             }\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MNIST_DATASETS' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Zl6bKEbGa2Ay",
        "colab_type": "code",
        "outputId": "5109c4a6-bdc2-4621-8d5b-5a2b35ae5b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels_feed, preds))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-677a9944203a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'labels_feed' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "c5xuDiGTi2Pv",
        "colab_type": "code",
        "outputId": "dd8f7495-7389-4fda-ece7-3f762849dc41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(labels_feed, preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[473   0   0   0   0   2   2   0   0   2]\n",
            " [  0 553   2   2   1   0   1   2   2   0]\n",
            " [  1  10 454   5   1   1   0   7   8   1]\n",
            " [  0   1   2 475   0   7   0   5   2   1]\n",
            " [  0   1   0   0 526   0   4   1   0   3]\n",
            " [  0   1   1   0   1 427   0   0   3   1]\n",
            " [  3   2   0   0   1   1 493   0   1   0]\n",
            " [  0   2   2   1   3   0   0 536   0   6]\n",
            " [  0   2   0   1   0   3   1   2 449   4]\n",
            " [  2   1   0   2   5   2   0   7   2 474]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6DmDZXWY0-VZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# graph = tf.GraphDef()\n",
        "# graph.ParseFromString(tf_model.SerializeToString())\n",
        "\n",
        "# with tf.Graph().as_default() as graph:\n",
        "#         # The name var will prefix every op/nodes in your graph\n",
        "#         # Since we load everything in a new graph, this is not needed\n",
        "#     tf.import_graph_def(graph, name=\"prefix\")\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}